{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu6fertWEyB0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainpath ='/content/preprocessed_train.csv'\n",
        "testpath = '/content/preprocessed_test.csv'\n",
        "evalpath = '/content/preprocessed_eval.csv'"
      ],
      "metadata": {
        "id": "3vM7RAeUFHbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(trainpath)\n",
        "test_df = pd.read_csv(testpath)\n",
        "eval_df = pd.read_csv(evalpath)"
      ],
      "metadata": {
        "id": "RICK0N5JFKNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "train_df['label'] = le.fit_transform(train_df['general'])\n",
        "test_df['label'] = le.fit_transform(test_df['general'])\n",
        "eval_df['label'] = le.fit_transform(eval_df['general'])"
      ],
      "metadata": {
        "id": "DriEoKUZFMH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report"
      ],
      "metadata": {
        "id": "ZFZf3LgRFNLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len=128):\n",
        "        self.texts = dataframe['review'].tolist()\n",
        "        self.labels = dataframe['label'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.label_mapping[self.labels[idx]])\n",
        "        return item"
      ],
      "metadata": {
        "id": "hLQ1JSMtFQgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"indobenchmark/indobert-base-p1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByQLjfC0FSCk",
        "outputId": "5453bc9f-3781-449d-c9a6-d4fda8ff2dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len=128):\n",
        "        self.texts = dataframe['review'].tolist()\n",
        "        self.labels = dataframe['label'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item"
      ],
      "metadata": {
        "id": "mMF90W9BFTGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SentimentDataset(train_df, tokenizer)\n",
        "test_dataset = SentimentDataset(test_df, tokenizer)\n",
        "eval_dataset = SentimentDataset(eval_df, tokenizer)"
      ],
      "metadata": {
        "id": "QmE4ihDpFUH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds, average='weighted')\n",
        "    recall = recall_score(labels, preds, average='weighted')\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "VmdagLlDFU6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy='epoch',\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_dir='./logs',\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "Q9mVyqXYFVrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "8w14u21ZFXEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "mDXmPbqDFX_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "uj6sts1mGqRs",
        "outputId": "0b9e34c9-38e6-445c-b0db-8c0f279b4520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='345' max='345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [345/345 04:56, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.345738</td>\n",
              "      <td>0.862144</td>\n",
              "      <td>0.872684</td>\n",
              "      <td>0.862144</td>\n",
              "      <td>0.864513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.314049</td>\n",
              "      <td>0.870897</td>\n",
              "      <td>0.873911</td>\n",
              "      <td>0.870897</td>\n",
              "      <td>0.871778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.436190</td>\n",
              "      <td>0.875274</td>\n",
              "      <td>0.874487</td>\n",
              "      <td>0.875274</td>\n",
              "      <td>0.874766</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=345, training_loss=0.29141124780627264, metrics={'train_runtime': 297.6839, 'train_samples_per_second': 18.402, 'train_steps_per_second': 1.159, 'total_flos': 360333825578496.0, 'train_loss': 0.29141124780627264, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics = trainer.evaluate(test_dataset)\n",
        "print(\"Test set metrics:\", test_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "U5iE01a6FaDb",
        "outputId": "f3f4da7f-b161-44b8-b5b2-fd0cd8ed2bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set metrics: {'eval_loss': 0.3525395393371582, 'eval_accuracy': 0.8986013986013986, 'eval_precision': 0.9020155102629329, 'eval_recall': 0.8986013986013986, 'eval_f1': 0.8997046210786668, 'eval_runtime': 2.1823, 'eval_samples_per_second': 131.053, 'eval_steps_per_second': 8.248, 'epoch': 3.0}\n"
          ]
        }
      ]
    }
  ]
}